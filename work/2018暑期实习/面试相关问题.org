#+LATEX_HEADER: \usepackage{xeCJK}
#+LATEX_HEADER: \setmainfont{"微软雅黑"}
#+ATTR_LATEX: :width 5cm :options angle=90
#+TITLE: 面试相关问题
#+AUTHOR: 杨 睿
#+EMAIL: yangruipis@163.com
#+KEYWORDS: 
#+OPTIONS: H:4 toc:t 


* 实习准备
** 印象最深的项目
VISAP
** 最难的问题以及如何解决

- 文本挖掘工具 匹配规则制定（根据表达式匹配）
  - 充分结合数据结构方面的知识：后缀表达式（逆波兰式）
  - 满足了分析师的新需求，优先级，或且非，括号（公司系统没有实现）
  - 优化了存储，仅通过索引进行操作（snowNLP借鉴)

- VISAP 空间作图  

** 最大的优缺点
优点：学习能力
缺点：急性子，想到什么就去做什么。解决办法：emacs 时间管理，包括任务类型，开始时间，结束时间，完成状态，优先级
** 读过哪些开源项目

- snowNLP
- costcla
- sklearn

** 有没有关注最前沿的机器学习动态
微软mmdnn 多深度学习平台切换

** 个人介绍

我叫杨睿，本科就读上海对外经贸大学统计学专业，后保研至数量经济学。我热爱数据和编程，有着较强的统计学基础，以及大量数学建模经验，对数据非常敏感。大二开始接触编程和数据挖掘，从R语言到C#到python，自学过基本的数据结构和算法，并且多次阅读了《机器学习》和《统计学习方法》。大四的时候用C#写过一款统计软件，研究生阶段从底层实现了自己的机器学习库，并且参加了诸多数据挖掘比赛，比如在中国大数据创新行动大赛中拿到一等奖，以及最近的东证期货杯拿到初赛一等奖。而我主要的两份实习均和数据挖掘有关，第一份实习主要是针对舆情数据进行建模和预测，第二份实习是将机器学习方法应用于量化交易当中。我的优势是学习能力强，乐于挑战新的东西（spark、docker）。

* 技巧
- 写代码时：先写一个很快能实现的答案，再和面试官口上说更好的答案。一方面不让面试官等，二来可以和面试官有的聊。
  
* 专业问题
** 机器学习
*** LASSO怎么求解
1. 坐标下降 O(mn)，针对可微的凸优化
2. 最小角回归 
*** 决策树剪枝
1. 前剪枝（设置参数）
2. 后剪枝：
   1. 误差降低剪枝，原始根节点和去掉一个节点后根节点在测试集上的误判数量对比，如果去掉后误判减少了，则实现剪枝
   2. 悲观剪枝，不需要测试集，二项分布渐进正态，连续修正因子，均值、方差为np、np(1-p)，当子树错误率大于等于叶子节点的错误率+一个标准差后，进行剪枝
*** 现在研究
金融复杂网络+空间计量
*** 想了解什么
工作状况、业务场景
*** SVM 和 LR 区别 与 联系
区别：
- 损失函数，LR：logistic loss， SVM：hinge loss
- 优化方法
- 适用范围：LR线性，考虑所有样本点，对异常值敏感；SVM只受支持向量影响
- LR适合大量数据，可用随机梯度或小批量梯度下降解决；SVM数据量大时训练慢，要找KKT条件
联系：
- LR类似不带核的支持向量机

*** 常用的统计量
- p值
- t值
- 

*** 如何判断凸优化
海森矩阵半定

*** libsvm和liblinear有什么区别
      libsvm主要解决通用典型分类问题
      liblinear 解决大规模是数据线性模型设计
*** 过拟合、欠拟合的特征、如何判断、如何处理
一个高方差、一个高偏差
学习曲线，交叉验证
LR：加正则
DT：剪枝
SVM：调整软间隔参数
NN：dropout
*** 随机森林 GBDT的区别
*** 损失函数类型
- hinge loss
- logistic loss
*** SVM 对偶问题的意义
凸二次规划对偶问题更好求解，根据KKT条件，只要计算少数几个支持向量的距离即可

*** Softmax回归是什么
V_i为V中i元素个数，softmax = e^{V_i} / \sum_j e^{V_j}
logistic回归是softmax在二分类情况下的退化
*** stacking 优缺点
优点： 提升效果，操作简单，训练可并行
缺点：容易过拟合
*** 是否了解mutual infomation、chi-square、LR前后向、树模型等特征选择方式
*** 机器学习算法调试（梯度检验）
根据极限的定义，损失函数的参数增加一个很小的量，用产生的delta除以该量，得到梯度，和实际计算梯度对比
*** 常用优化算法
- SGD + momentum（梯度为F，动量为摩擦力，学习率为速度，F=ma）
- （不会就别说）adaDelta：每个参数计算相应的学习率，加入动量momentum，防止学习率衰减或梯度消失
*** 梯度下降和牛顿法区别
一个是平面逼近，一个是曲面逼近
一个是一阶偏导，一个是二阶偏导矩阵
*** SVM 原理
距离超平面最近的不同类别的点几何间隔最大化
*** SVM原问题与对偶问题关系
原问题是在最大化alpha的前提下最小化w，对偶问题时再最小化w的前提下最大化alpha
*** KKT条件应用
互补对偶条件 α_i (y_i (w^T x + b) - 1) = 0
1. α = 0
2. α != 0
*** TF-IDF 算法
TF：词在该文本中出现频率
IDF： log(总文本数 / 包含该文本的数目)
缺点：忽略上下文，改进：word2vec doc2vec

*** TODO LSTM GRU区别
- State "TODO"       from ""           [2018-03-17 周六 09:17]
LSTM：输入门、输出门、遗忘门
GRU：更加简单实现，更新门（前一时刻状态信息被带入当前状态）重置门（忽略前一时刻状态信息的程度）
*** EM 与 kmeans 的关系
https://www.cnblogs.com/rong86/p/3517573.html
*** kmeans优化、效果评估、k值确定，初始点确定，优缺点
效果评估：
- 轮廓系数
- 组间组内距离

K值确定：
- 迭代，根据效果取最好的
- 层次聚类

初始点确定：
选择第一个初始点的第一个值后，找离他最远的，作为第二个值，再找离这两个点中心最远的，作为第三个，依次类推

优缺点：
优点：原理简单，容易理解
缺点：算法每次迭代需要计算每个点到每一个中心距离，复杂度高；K值，初始值难以确定；不稳定，初始值不一样导致每次得到结果不一样

优化：
- kmeans++ (初始点如上方法确定）
- mini-batch kmeans 每次选取一部分数据进行优化
- KD树，类似KNN中找最近邻的问题，用kd树解决

*** lasso 在 0处不可导怎么办
通过坐标下降法(非梯度方法）求解
*** SVD SVD++
SVD: 矩阵分解+baseline mode,考虑每个样本的偏移项
SVD++: SVD基础上引入隐式反馈,比如用户的浏览数据,历史评分数据
*** TODO LR分布式代码
- State "TODO"       from ""           [2018-03-17 周六 09:18]

*** GBDT 正则化
1. 类似adaboost，添加步长(学习率)，较小的步长需要较大的迭代次数。
2. 只选择一部分样本，无放回抽样，比例一般在50%-80%
3. CART树剪枝

*** sigmoid函数 梯度爆炸与梯度消失
在神经网络反向传播中，需要对每一曾的偏导数相乘，如果是sigmoid函数，其最大梯度为0.25，相乘后容易产生梯度消失，可以尝试使用Relu函数替代

*** 非平衡数据如何使用交叉验证
*Use K-fold Cross-Validation in the right way*
 
It is noteworthy that cross-validation should be applied properly while using over-sampling method to address imbalance problems.

Keep in mind that over-sampling takes observed rare samples and applies bootstrapping to generate new random data based on a distribution function. If cross-validation is applied after over-sampling, basically what we are doing is overfitting our model to a specific artificial bootstrapping result. That is why cross-validation should always be done before over-sampling the data, just as how feature selection should be implemented. Only by resampling the data repeatedly, randomness can be introduced into the dataset to make sure that there won’t be an overfitting problem.

*** K折交叉验证 K确定
不知道
*** SVM推导
*** lasso求解推导：
1. 坐标下降法
2. 最小角回归法（LRS）
*** logistic值表示概率吗
表示，由公式推导可知
*** 为什么logistic选用sigmoid函数
1. 优良性质：包括映射空间、求导方便，等等
2. 最大熵推导得到 或者是指数分布族推导

指数族推导：
Y|X 服从伯努利分布，其密度函数为 p^y (1-p)^{(1-y)} 转化为指数形式，可得到ln(p/(1-p))， 令其为phi ，求解p，得到p为sigmoid函数
*** 如何度量两个分布之间的差异性
通过交叉熵（按照真实分布p来衡量识别一个样本的所需要的编码长度的期望(即平均编码长度)）

H(p, q) = -\sum p(i) log q(i) >= H(p)
*** 说一下Adaboost，权值更新公式。当弱分类器是LR时，每个样本的的权重是w1，w2...,写出最终的决策公式
w = w * exp(- alpha y_i f(x_i)) y_i = -1 或 1
*** GBDT如何进行特征选择
依据：每个特征能够让分裂后平方损失减少的值

*** 什么是最大后验估计
优化p(w|x)而不是p(x|w)

*** 对缺失值敏感的模型
=以决策树为原型的模型优于依赖距离度量的模型= 

1. 树模型可以在大多数缺失值情况下使用
2. 涉及到距离度量的模型对缺失值敏感，如KNN, SVM
3. 线性模型的代价函数往往涉及到距离的计算，计算预测值和真实值之间的差别，容易导致对缺失值敏感
4. 神经网络鲁棒性强，对缺失值不敏感
5. 贝叶斯模型对缺失值不敏感，数据量小的时候首推贝叶斯

*** TODO 对异常值敏感的模型
- State "TODO"       from ""           [2018-04-04 周三 19:13]

- logistic模型显然对异常值敏感
- SVM、KNN对异常值不敏感
- 。。。

*** 为什么需要标准化
1. 距离没有意义
2.  如果多个特征之间数值差异较大，那么收敛速度会很慢（吴恩达）

*** 什么时候需要标准化
1. 基于距离的模型
2. 加入正则项的模型
3. 量纲差异非常大的模型（为了加快训练速度）

*** 生成式模型和判别式模型
生成式：对p(x, y)建模：朴素贝叶斯，LDA，隐马尔科夫，混合高斯
判别式：对P(y|x)建模：LR,SVM,决策树,Boosting，条件随机场，区分度训练
*** 矩阵计算效率：

A_{pxq} x B_{qxr}的效率看pqr的大小，
*** 如果不考虑均值，PCA完全等价于SVD

*** 降维方法
- Lasso
- PCA
- 小波分析
- 线性判别LDA
- 拉普拉斯映射（基于图的降维）
- SVD
- LLE局部线性嵌入（基于图的降维）

*** 不同分类器的VC维

- n维空间中线性超平面的VC维是n+1，n为x的维度
- 高斯核分类器的VC维是 正无穷
- 最近邻： 正无穷 （解释了为何KNN会过拟合）
- 神经网络：参数数目
- 决策树： 节点数目 + 1

*** VC维的作用
证明误差上界，从而进行模型选择。VC维越大，分类能力越强，模型越复杂，越容易过拟合

但是实际上模型的误差和理论上有一些出入，因此最好的模型选择方法还是：
- CV
- AIC
- BIC
  
*** one-class SVM
ref: https://blog.csdn.net/sinat_26917383/article/details/76647272
对单类样本增加约束，如是boundary离高维空间原点最远，同时加入松弛变量，对异常点进行检验
理解：构造一个超高维球，把数据尽可能包起来，同时又不受outlier影响

*** kmeans质心类型：除了曼哈顿距离是中位数，其他的都是均值
注意：bregman散度也是距离度量的一种
*** 决策规则有哪些

**** 最小风险贝叶斯

**** 最小错误率贝叶斯

**** 最大最小风险
**** 序贯分类法

*** 激活函数类型和对比、如何选择

1. sigmoid
优点：求导方便
缺点：计算量大，易导致梯度消失
2. tanh
优点：零均值，在特征相差明显时效果较好，比sigmoid效果好
缺点：计算量大，收敛速度慢
3. ReLu ( max(0, x) )
优点：(1) 训练速度非常快 (2)不会产生梯度消失 (3)一定程度上降低了模型的复杂度，使更稀疏
缺点：learning rate（梯度下降参数）过大时神经元十分脆弱，导致 =神经元死亡= 即输出永远是0，参数不再更新
4. pReLu
pReLu = x, if x > 0
pReLu = ax, if x < 0
避免了死神经元的问题
5. softmax
e^z / sum_k^K e^k
z为某神经元的线性值，K为当前层所有神经元的线性值。softmax特点是多分类，如果某一值明显大于其他值，那么softmax后会明显趋于1，其他的都趋于0，就完成了分类目的。

选择：
首选通用的ReLu，如果出现死神经元，上PReLu，再和Sigmoid、tanh等对比，找最好的

*** 神经网络相关问题
1. 神经网络可以处理冗余特征
2. ANN（人工神经网络）是至少含有一个隐含层的多层神经网络
3. 神经网络在训练过程中对噪声不鲁棒
*** 线性分类器最佳准则

- 感知准则函数
- 支持向量机
- Fisher准则

~贝叶斯分类器不是线性分类器~

*** 二次准则函数的 H-K算法
基于二次准则函数的H-K算法较之于感知器算法的优点

- H-K 算法的思想很朴实，就是在最小均方误差准则下求得权矢量。
- 它相对于感知器算法的优点在于，它适用于线性可分和非线性可分的情况。
- 对于线性可分的情况，给出最优权矢量，
- 对于非线性可分的情况，能够判别出来，以退出迭代过程。

*** TODO 经验风险、结构风险、置信风险
- State "TODO"       from ""           [2018-04-07 周六 16:20]

*** 统计判别准则
1. 先验概率已知：
   - 贝叶斯最小错误率准则
   - 贝叶斯最小风险准则
2. 先验概率未知
   - N-P准则：限定一类错误率为常数而使得另外一类错误率最小的决策
   - 最小最大损失准则：解决最小损失规则时先验概率未知或难以计算的问题的


*** TODO 支持向量回归
- State "TODO"       from ""           [2018-04-10 周二 14:33]

*** 哪些情况可以实现稀疏
- 向量非0元素个数（L0范数）
- 向量元素绝对值之和（L1范数）

*** 梯度消失、梯度爆炸的表现以及解决办法

**** 梯度消失
表现： 损失函数值变化非常缓慢
解决办法：
- 换用ReLu激活函数
- 使用batch normalization

=注意：= 调大调小batch size 和 learning rate 都没法解决该问题

**** TODO 梯度爆炸
- State "TODO"       from ""           [2018-05-13 日 14:34]

*** 非平衡数据交叉验证

1. 如果在采样之后进行交叉验证，将会导致 =过拟合= 问题

[[file:pics/cv1.jpeg]]

见上图，留一法交叉验证，显然他将生成的少数类样本拆开，一个做训练，一个做预测，因此产生了过拟合问题

如果是下图的处理方法则正确：


[[file:pics/cv2.jpeg]]



2. 如果在采样之前进行交叉验证，则容易导致训练集中没有少数类
  
   


*** 图模型

ref: 
- https://blog.csdn.net/wgdzz/article/details/48478813

LR与NB最大的区别是前者是判别式,后者是生成式. 而朴素贝叶斯可以转化为有向图模型, LR可以转化为无向图模型, 
CRF也是无向图模型, LR可以看做最简单的CRF模型



** 数据库
*** 四大属性
ACID，原子性，一致性，持久性，隔离性

*** 优化
https://www.zhihu.com/question/19719997
https://www.cnblogs.com/downey/p/5302088.html

*** Hive mysql 区别

1. Hive基于hadoop上，存储在HDFS中
2. Hive不支持对数据的修改和添加
3. Hive没有索引，通过分布式暴力扫描，因此访问延迟较高，不适合在线数据查询
4. 由于建立在集群之上，所以支持超大规模数据

*** Union 相当于取并集，可改写成or

*** MYSQL返回null
1. count(*) 一定不返回null
2. sum()、max() 等当对象不存在时返回null而不是0，
3. 如果希望他返回0用于下一步计算，则可以：
   - isnull(sum(cnt),0)  判断是否为空，如果为则返回0
   - COALESCE(SUM(name),0) # 返回第一个非空的值，此时如果sum为空，则返回0

*** mysql练习题

**** 

** 计算机

*** python装饰器
#+BEGIN_SRC python
from functools import wraps

def timeit(function):
    @wraps(function)
    def func_time(*args, **kwargs):
        t0 = time.time()
        result = function(*args, **kwargs)
        t1 = time.time()
        print(t1 - t0)
    return result
return func_time

@timeit
#+END_SRC

*** python垃圾回收
引用计数，当计数为0时，进行回收

导致引用计数+1的情况：
- 对象被创建，例如a=23
- 对象被引用，例如b=a
- 对象被作为参数，传入到一个函数中，例如func(a)
- 对象作为一个元素，存储在容器中，例如list1=[a,a]

导致引用计数-1的情况：
- 对象的别名被显式销毁，例如del a
- 对象的别名被赋予新的对象，例如a=24
- 一个对象离开它的作用域，例如f函数执行完毕时，func函数中的局部变量（全局变量不会）
- 对象所在的容器被销毁，或从容器中删除对象

*** python多重继承

python3: 深度优先+从左到右
*** python classmethod
- classmethod为类中装饰器，类似于staticmethod
- classmethod只接受cls参数，表示当前调用他的类
- 无论是什么类（父类，子类等）调用classmethod，传入的都是调用类本身
*** 继承、封装、多态

*** 接口、抽象类

接口实现动作，抽象类告诉这个是什么
*** 进程、线程区别
1. 进程类似工厂，线程类似里面每一个生产线
2. IO密集型用多线程、CPU密集型用多进程
*** TODO python动态语言还是静态语言，区别
- State "TODO"       from ""           [2018-03-31 周六 16:12]

python是动态语言，核心区别：在执行时能够改变其结构，将静态语言编译时所作的事情推迟到执行时进行

比如，申明b = B()，你可以再加入b的属性如b.test = None，即是b已经被实例化了，依然可以加入

~注意：~ 动态类型指变量不需要进行类型申明，大部分动态类型语言都是动态语言，但是不是动态语言的核心区别

*** 平均查找长度
查找时需要比较的平均次数

1. 分块查找
又称索引查找，由分块有序的索引表和线性表组成
- 若以顺序查找方式来确定元素所在的块，则平均查找长度为：(b+1)/2+(s+1)/2，其中b代表索引表的长度(即总块数)，s代表块内所含元素的个数
- 若以二叉查找确定元素所在块，则平均查找长度为 log_2(b+1)-1 + (s+1)/2
- 若以hash查找方式确定所在块，则平均查找长度为 (s+1)/2

2. 二分查找
2^树的高度d - 1 = 元素总个数n，所以 d = log_2(n+1)，每一层只需要比较一次，而最后一层不需要比较，所以平均查找长度为 log_2 (n+1) - 1

3. 顺序查找
平均查找长度为(1+n)/2 ，自己想想就知道了。

*** 可变对象和不可变对象

- dict，list是可变对象，int, str, float, tuple是不可变对象，改变的话必须重新开辟内存地址
- 注意0-256和257- 的区别，前者在启动时已经开辟好，后者还没有
- 注意 a = [1,2,3], b = a 时， b += [4] 和 b = b + [4]区别，前者相当于a调用了a.extend([4])，所以b和a都改变，后者重新赋予了地址，只有b改变a不变
- a = [1,2,3], a[:] 和a的区别

*** 32位和64位系统寻址空间

| 类型   | 32位 | 64位 |
|--------+------+------|
| Bool   |    1 |    1 |
| char   |    1 |    1 |
| short  |    2 |    2 |
| int    |    4 |    4 |
| =long= |    4 |    8 |
| float  |    4 |    4 |
| double |    8 |    8 |
| =指针= |    4 |    8 |

=对于结构体，要考虑其内存布局=
- 如果是相同类型，则相加即可，比如：
#+BEGIN_SRC c
struct c
{
　　char a;
　　char b[2];
　　char c[4];
}str3;
#+END_SRC

由于都为char类型，所以不必开辟新的单元，占用字节数为 1*1 + 1*2 + 1*4 = 7

- 而如果是不同类型，如
#+BEGIN_SRC c
struct A
{
　　char a;
　　int b;
　　short c;
}str1;
#+END_SRC
a占1个字节，b占4个字节，c占2个字节，存放结构如下
| a |   |   |   |
| b | b | b | b |
| c | c |   |   | 
所以为 4 * 3

而如果是下面这种情况，颠倒了b和c：
#+BEGIN_SRC c
struct A
{
　　char a;
　　short c;
　　int b;
}str1;
#+END_SRC  
则存放结果如下：
| a | c | c |   |
| b | b | b | b | 
所以需要 2*4 = 8个字节

*** 接口
接口是一种引用类型，在接口中可以申明方法、属性、索引器和事件，但是不能申明共有域或私有的成员变量

*** 面向对象原则
面向对象设计原则有6个：开放封闭原则，单一职责原则，依赖倒置原则，Liskov替换原则，迪米特法则和接口隔离原则或合成/聚合复用原则

*** SecondaryNameNode
*** 循环队列

由顺序表构造的队列容易出现问题：
a = queue(3) 长度为3的队列
a.inqueue(1)
a.inqueue(2)
a.inqueue(3)

a.dequeue()
a.dequeue()

a.inqueue(4) # 此时会出问题，虽然队列有空位，但实际上顺序表构造的队列已经到头了，此时只能全部移下去，复杂度O(n)

因此，我们通过循环链表构建循环队列：

[[file:pics/queue.png]]

由于会遇到后面元素索引小于前面元素的情况，因此其具体个数由：(rear - font + max)%max 得到，其中rear指向队尾元素 ~下一个元素~

*** 给定n个入栈元素，问出栈可能数目

卡特兰数： f(n) = f(0)f(n-1) + f(1)f(n-2) + ... + f(n-1)f(0)

*** C++ 相关问题

1. 指针

   - int *p ：初始化一个空指针p
   - p = &x ：将指向x的内存空间赋值给指针p，如果x被释放，那么*p则为空
   - *p = x ：将x的值赋值给p所指向的地址的值，如果p刚刚完成初始化，还没有指向任何地址，则操作非法
   - *p = new int(x)：同样非法操作，*p无法赋值一个地址
   - p = new int(x)： 包括了两步：(1) 让p指向一个不会自动释放的地址; (2)将x的值赋值给改地址的值
    
2. ++x和x++

   - ++x运算优先级最高，往往参与运算之前加1
   - 而x++运算优先级最低，往往参与运算之后加1

3. 面向对象

   - 继承后的访问情况
     - 私有成员不能被继承
     - 保护成员可被继承，但不能被外部访问
     - 公有继承、保护继承、私有继承的不同点：
       [[file:pics/inherit.png]]

*** 计算机网络相关

ref:
- https://blog.csdn.net/hsd2012/article/details/52435057
    

*** 编译原理相关

1. 解释型语言和编译型语言区别

   - 解释型语言不生成目标程序；而编译语言生成
   - 解释型语言通过中间代码生成目标代码；而编译型语言直接生成目标代码（目标代码：机器可直接执行的代码，包括字节码(JAVA)和机器码(C)）
   - 编译只需要做一次，效率高，可以脱离语言环境；而解释型语言每次运行时逐行翻译，灵活，可以快速部署，但是性能较差

   - 代表的解释型语言：JavaScript、Python、Erlang、PHP、Perl、Ruby
   - 代表的编译型语言：C、C++、Pascal、Object-C

   ~注意：java是一个另类，jvm解释执行，而jit编译执行，不过~
  
2. 动态语言静态语言区别
   
   - 动态语言在运行时可以改变其 ~代码结构~ ，比如增加新的函数、对象、成员属性等等：C#(通过反射机制), python, javascript, PHP
   - 静态语言，与其相反：Java, C, C++

3. 动态类型语言和静态类型语言

   - 动态类型语言：运行时候才进行类型检查，指的是 ~数据结构~ ：Python、Ruby、Erlang、JavaScript、swift、PHP、Perl
   - 静态类型语言：C、C++、C#、Java、Object-C

4. 强类型和弱类型
   - 强类型：一旦一个变量被指定了某个数据类型，如果不经过强制类型转换，那么它就永远是这个数据类型：Java、C#、Python、Object-C、Ruby
   - 弱类型：数据类型可以被忽略，一个变量可以赋不同数据类型的值。一旦给一个整型变量a赋一个字符串值，那么a就变成字符类型：JavaScript、PHP、C、C++




*** 
** 算法
*** 长为n的数组前K个最大的数
维护一个长为K的数组，排序（快排），或者是用二叉树存，开始读n-k个数，每次数来了跟最小的比，如果大了，则插入，如果小了，继续
*** 长为m和长为n的两个字符串，找最长公共子串
用 mxn 的矩阵存储在某一位置是否匹配，且如果左上角非0，则该元素在左上角基础上加1，找到矩阵中最大的元素，以及位置
*** 数轴上从左到右有n个点a[0],a[1]…,a[n-1]，给定一根长度为L的绳子，求绳子最多能覆盖其中的几个点。要求算法复杂度为o(n)


#+BEGIN_SRC python :results output

def cover(a: list, l: int):
    begin = 0
    end = 1
    max_cover = 1
    while end < len(a):
        if a[end] - a[begin] > l:
            # print(max_cover)
            begin += 1
        else:
            max_cover = max(end-begin+1, max_cover)
            end += 1
    return max_cover

a = cover([1,3,4,5,6,8,10], 4)
print(a)
#+END_SRC

#+RESULTS:
: 4

*** 已n知二叉树前序和中序遍历结果，求后序遍历结果
关键点：
1. 根据前序和后序确定根节点，前序是第一个，后序是最后一个
2. 在中序中按根节点分割，左侧再在前序或后序中找根节点，如此递归
*** 统计出现次数最多的K个数字
先hash统计词频，在找前K个最大的

*** 单链表 反转
通过三个指针存储相邻的三个节点

*** 最长回文子串/回文子序列
**** 子串
动态规划，f(i,j) 表示第i个到第j个元素是否为回文
- 如果 i == j 是的
- 如果 j - i == 1 且 nums[i] == nums[j] ，是的
- 其他 返回 f(i+1, j-1)

**** 子序列
动态规划：
- 如果首尾两个元素相同 则f(i,j) = f(i+1, j-1) + 2
- 如果首尾两个元素不同 则f(i,j) = max(f(i+1, j), f(i, j-1))
- 如果 i == j:返回1
- 如果 i == j - 1，如果两值相等，则返回2，否则返回0

*** 最长重复子串
1. 找出所有后缀子串
2. 自然排序
3. 找相邻后缀子串的最大公共前缀

*** 最多连续重复子串

deabcabcabe 输出abc
eabcabcabe
abcabcabe   *
bcabcabe
cabcabe
abcabe      *
bcabe
cabe
abe         *
be
e

*** 最长无重复子串
双指针法

*** 全排列问题

问题1. 列出输入列表所有全排列结果

递归得到 nums[1:]的全排序，循环n-1次，将nums[0]插入到nums[1:]得到的全排序数组中每一个位置中去

问题2. 字典序问题

首先从后往前找到最大的非增序列 [k+1:]，其次找到 nums[k+1:]中比nums[k]大的最小的数，和nums[k]交换，然后nums[k+1:]重新逆序排序

*** 最长公共子序列 / 子串

1. 最长公共子序列：对 s1 和 s2 
- 如果有一个长度为0， 则返回0
- 如果s1[-1] == s2[-1] 那么返回 f(s1[:-1], s2[:-1]) + 1
- 如果不等，则返回 max(f(s1[:-1], s2), f(s1, s2[:-1]))

2. 最长公共子串：构建矩阵，元素相同为1，且和坐上角的相加，最后取矩阵最大值

*** m个水果放在n个盘子里，有几种放法（盘子可以为空，115 和511是同一种放法）

1. 当 m 为0 或者 n 为 1时，有1种放法
2. 当 m < n时，最小有n-m个盘子不放，因此对结果不影响，有 f(m,m)种
3. 当 m >= n时，有两种情况：
   1. 最少有一个盘子没放，此时一个盘子不影响结果的，等于 f(m, n-1)
   2. 每个盘子都放放，那么每个盘子拿出一个是不影响的，等于 f(m-n, n)
   所以此时整个情况就是 f(m,n) = f(m, n-1) + f(m-n, n)

*** 堆以及堆的相关问题
1. 堆排序
2. topk问题 O(nlogk)

*** 快排相关问题
1. 快排
2. topk问题 O(n)
3. the k_th 问题（第k个）

*** 动态规划问题

=性质：=
1. 最优子结构：最优解下的所有子结构的解也是最优的
2. 无后效性：当前若干状态一旦确定，此后的演变过程只和这若干状态有关，和之前到达该状态的路径无关

=核心=
1. 子问题
2. 边界
3. 转移方程

*** DONE 排序算法及其复杂度、稳定性、精简性


|----------+----------+----------+----------+--------------+----------+----------|
| 算法名称 | 最好     | 最坏     | 平均     | 空间         | 稳定性   | 精简排序 |
|----------+----------+----------+----------+--------------+----------+----------|
| 冒泡排序 | O(n)     | O(n^2)   | O(n^2)   | O(1)         | 稳定     | 否       |
| 选择排序 | O(n^2)   | O(n^2)   | O(n^2)   | O(1)         | 不稳定 1 | 否       |
| 插入排序 | O(n)     | O(n^2)   | O(n^2)   | O(1)         | 稳定     | 是       |
| 希尔排序 | O(n)     | O(nlogn) |          | O(1)         | 不稳定   |          |
| 堆排序   | O(nlogn) | O(nlogn) | O(nlogn) | O(1)         | 不稳定   | 否       |
| 归并排序 | O(n)     | O(nlogn) | O(nlogn) | O(n)         | 稳定     | 是       |
| 快速排序 | O(nlogn) | O(n^2)   | O(nlogn) | O(logn)~O(n) | 不稳定   | 是       |
| 二叉排序 |          | O(n^2)   | O(nlogn) | O(n)         | 不一定   |          |
| 计数排序 | O(n+k)   |          |          | O(n+k)       | 稳定     | 否       |
| 基数排序 | O(n)     |          |          | O(n)         | 稳定     | 否       |
| 桶排序   | O(n+k)   |          |          | O(n+k)       | 稳定     | 否       |
|----------+----------+----------+----------+--------------+----------+----------|
*以上所有log均是以2为低
*1 用链表实现的选择排序则是稳定的
*精简排序是指排序过程中每一对元素只会比较一次
*建堆复杂度是O(1)

*** 霍夫曼树

将元素排序，每次取最小的元素作为左右节点，并且他们的和作为新节点添加到待选的元素中，重复选择最小的元素作为左右节点。

=带权路径长度=

每一个叶节点的权重，乘以其所在的深度（经过的所有非叶子节点数），加总

一般情况下，我们使左子树带权路径长度小于右子树

*** K sum问题
- 2 sum: 
  - 排序数组：头尾双指针法 O(N)
  - 未排序数组：hash法 O(N)
- 3 sum:
  - 排序，固定其中一个，对剩余的进行2sum，O(N^2)
- 4 sum:
  - (1) 数组元素排除自身，两两组合，得到(n-1)!组数，将他们求和，记录在结构体中，保存求和和每个数的下标，复杂度为O(N^2)；(2) 将所有和排序，进行双指针搜索，当两个指针对应元素有相同的下标时跳过，复杂度为O(N^2LogN)
- k sum:
  - 固定一个数后递归 k-1 sum，O(n^{k-1})

*** DONE 有向图的拓扑排序（确定是否有环）
- State "DONE"       from "TODO"       [2018-05-31 四 19:43]

1. 在有向图中选一个没有前驱的顶点并且输出
2. 从图中删除该顶点和所有以它为尾的弧（白话就是：删除所有和它有关的边）
3. 重复上述两步，直至所有顶点输出，或者当前图中不存在无前驱的顶点为止，后者代表我们的有向图是有环的，因此，也可以通过拓扑排序来判断一个图是否有环。

*** B树，B-树，B+树
**** BST树：二叉搜索树
**** B-树(B树）：多叉树，任何一个关键字只出现在一个节点中，搜索有可能在非叶子节点结束，搜索性能等价于在关键字全集内做一次二分查找，支持顺序和随机索引
- m阶B-树关键字个数：最多m-1，最少m/2-1向上取整
- 对于n个关键字m阶的B-树，从根结点到关键字所在结点的路径上路过的结点数不超过 log_{m/2}((n+1)/2) + 1

****  B+树：B-的变体，多叉树，所有关键字都在叶子节点出现，只会在叶子节点结束搜索，适合做文件系统索引，支持顺序和随机索引
*** 二叉树类型

**** 完美二叉树 perfect
每一层都被完美填充

**** 完全二叉树 complete
除了最后一层每一层都被完美填充

**** 完满二叉树 Full
每一个节点必须具有左右两个节点

=关系=

- perfect 一定 complete 和 full，反之不一定
- complete可能是full，也可能不是，反之一样
- complete + full 可能是perfect，也可能不是

*** 一些图的算法
1. 最小生成树：
   - Prim，稠密图，时间复杂度O(N^2)，与边的数目无关，N为节点数目
   - kruskal，稀疏图，时间复杂度为O(eloge)，与边的数目有关，e为边的数目
2. 最短路径
   - floyd，多源最短路
   - dijkstra ，单源最短路，且权重非负（如果全为负则转为正）
   - bellman，可计算负权回路，
   - spfa，类似bellman
*** 树的遍历

**** 深度优先

***** 递归前序遍历


#+BEGIN_SRC python :results output
  def preOrderTraverse(root):
      if not root:
          return
      print(root.value)
      preOrderTraverse(root.left)
      preOrderTraverse(root.right)
#+END_SRC

***** 非递归前序遍历
#+BEGIN_SRC python
def pre_order_traverse_NC(root):
    stack = [root]
    while stack:
        temp = stack.pop()
        print(temp.value)
        if temp.right:
            stack.append(temp.right)
        if temp.left:
            stack.append(temp.left)
#+END_SRC

***** 递归中序遍历

#+BEGIN_SRC python
def in_order_traverse(root):
    if not root:
        return
    in_order_traverse(root.left)
    print(root.value)
    in_order_traverse(root.right)
#+END_SRC
***** 非递归中序遍历
#+BEGIN_SRC python
def in_order_traverse_NC(root):
    stack = []
    temp = root
    while temp or stack:
        if temp:
            stack.append(temp)
            temp = temp.left
        else:
            temp = stack.pop()
            print(temp.value)
            temp = temp.right
#+END_SRC
***** 递归后序遍历
#+BEGIN_SRC python
def post_order_traverse(root):
    if not root:
        return
    post_order_traverse(root.left)
    post_order_traverse(root.right)
    print(root.value)
#+END_SRC

***** 非递归后序遍历
#+BEGIN_SRC python
# 双栈法
def post_order_traverse_NC1(root):
    stack1 = [root]
    stack2 = []
    while stack1:
        temp = stack1.pop()
        stack2.append(temp)
        if temp.left:
            stack1.append(temp.left)
        if temp.right:
            stack2.append(temp.right)
    while stack2:
        print(stack2.pop())
#+END_SRC

#+BEGIN_SRC python
# 单栈法
def post_order_traverse_NC2(root):
    stack = [root]
    bool_dic = {}    # 记录节点的左右是否已经入栈过
    while stack:
        node = stack[-1]
        if (not node.left and not node.right) or node in bool_dic:
            print(stack.pop().value)

        if node not in bool_dic:
            bool_dic[node] = True
            if node.right:
                stack.append(node.right)
            if node.left:
                stack.append(node.left)
#+END_SRC

**** 广度优先(非递归）
#+BEGIN_SRC python
def breadth_first_traverse(root):
    queue = [root]

    while queue:
        temp = queue.pop(0)
        print(temp.value)
        if temp.left:
            queue.append(temp.left)
        if temp.right:
            queue.append(temp.right)
#+END_SRC

*** 最大乘积子序列
#+BEGIN_SRC python
def foo(arr):
    l_max = [arr[0]]
    l_min = [arr[0]]
    for i in arr:
        l_max.append(max(max(i*l_max[-1], i*l_min[-1]), i))
        l_min.append(min(min(i*l_max[-1], i*l_min[-1]), i))
    return max(l_max+l_min)
#+END_SRC


** 概率题
*** 二项分布当n很大, 可以用泊松分布或者是高斯分布逼近
*** 抛硬币停止的期望

例：连续出现“正反正”的期望次数（如果抛完最后一个为N，那么期望次数为抛出第一个“正”时的次数N-2）

设：

| 期望次数 | 形式     |
| e0       | ""       |
| e1       | "正"     |
| e2       | "正反"   |
| e3 = 0   | "正反正" |

1. 当什么都没抛出来的时候，有1/2的概率抛出"正"，对应期望e1，有1/2的概率抛出"反"，对应期望e0，因此有
e0 = 1/2 (1 + e1) + 1/2 (1 + e0)
2. 当抛出正的时候，如果再抛出反，则对应e2；如果再抛出正，那么等同于e1，因此有
e1 = 1/2 (1 + e2) + 1/2 (1 + e1)
3. 当抛出“正反”时，如果再抛出正，则对应e3；如果再抛出反，则一切重来，对应e0，因此有
e2 = 1/2 (1 + e3) + 1/2 (1 + e0)

求解e0即是最终答案

** 智力题
*** 最佳停时问题
37% 可用蒙特卡洛模拟做


* 企业笔试题
** 美团
=3月22日笔试=

1. 记两个字符串的相似度为相同位置上不同字符的个数（两字符串必须等长），现有字符串S和字符串T，|S| >= |T|，则S一共有|S| - |T| + 1个和T等长的子串，计算每个子串和T的相似度的总和，字符串中只有a或者b两个元素。暴力遍历，O(|S| |T|)

2. 给很多个数，找出其不能拼成的最小正整数：
   - "0123" -> 4
   - "123456789" -> 10
   - "11234567890" -> 22

** 携程

=3.28日笔试=

*** 问答题
- 为什么说ReLu激活函数好于sigmoid函数和tanh函数
- 已知父亲双眼皮的概率，母亲为单眼皮，求生的第一个孩子双眼皮的概率；已知生的第一个孩子为双眼皮，求第二个孩子为双眼皮的概率（贝叶斯，先确定父亲双眼皮的条件概率）

*** 编程题

给定有向图，求最长路径，如果有环则返回-1（深度优先搜索）

** 京东
*** 1. 因数分解

将给定的数分解为一个奇数乘以一个偶数的形式，如有多个解，取偶数最小的解

~分析：~
右侧如果是2的奇数倍，那么左侧乘以该奇数依然是奇数，而右侧的2是最小的解，因此右侧必定只能是2的k次方


*** 2. 回文串

将给定的字符串剔除掉一定字符后可以变成回文串，问剔除的方案有多少种，如果剔除字符串按顺序排列一样，则是同一种方法；空串不是回文串

比如输入 "ABA"，输出5
~动态规划~
[[file:pics/jd1.png]]

*** 3. 象棋中的马
给定棋盘中的位置和允许的步数，求马从（0，0）走到该位置的方案有多少种

~动态规划~

#+BEGIN_SRC python
def foo4(k, x, y):
    k_list = []

    for i in range(k+1):
        x_y = [[0 for j in range(9)] for w in range(9)]
        if i == 0:
            x_y[0][0] = 1
        else:
            for m in range(9):
                for n in range(9):
                    s = 0
                    if m - 2 >= 0 and n - 1 >= 0:
                        s += k_list[-1][m-2][n-1]
                    if m - 1 >= 0 and n - 2 >= 0:
                        s += k_list[-1][m-1][n-2]
                    if m - 2 >= 0 and n + 1 <= 8:
                        s += k_list[-1][m-2][n+1]
                    if m - 1 >= 0 and n + 2 <= 8:
                        s += k_list[-1][m-1][n+2]
                    if m + 2 <= 8 and n - 1 >= 0:
                        s += k_list[-1][m + 2][n - 1]
                    if m + 1 <= 8 and n - 2 >= 0:
                        s += k_list[-1][m + 1][n - 2]
                    if m + 2 <= 8 and n + 1 <= 8:
                        s += k_list[-1][m + 2][n + 1]
                    if m + 1 <=8 and n + 2 <= 8:
                        s += k_list[-1][m + 1][n + 2]
                    x_y[m][n] += s
        k_list.append(x_y)
    return k_list[-1][x][y]
#+END_SRC








** paypal
*** 版本号检查
给定根节点，以及一个树状结构（多叉树），对给定的目标，求其距离根节点最近的节点
显然，广度优先搜索
[[file:pics/paypal1.png]]
*** 表达式计算
要求：
1. 识别错误，不能有负号，不能有小数，只有+，-，*号以及括号，只有符号周围可以有空格，否则报Error
2. 表达式计算， 优先级： "("=")" > "+" = "-" > "*"
*** 屠龙宝刀一刀999

多个节点组成了多张图，对每一个封闭的图，每增加一个节点，那么所有节点的值都会加一，你现在可以踢掉其中任意一个节点以及其所有的边，对应与其有关的图内节点值也要减去1，但是你要使踢掉之后所有节点的最大值最小。求你要踢掉哪个节点，且最小值是多少
[[file:pics/paypal3.png]]


